{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of beta_version0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "A7yDjsMyN9uP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Confirm TensorFlow can see the GPU\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Pw_DXNqXROBI",
        "colab_type": "code",
        "outputId": "6541c4b9-f5ef-46e8-eec6-66a20deddb95",
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d1680108c58e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "dri7Beu1O8sD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Loading libraries\n"
      ]
    },
    {
      "metadata": {
        "id": "1nTSFLhj8Zux",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten, InputLayer\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
        "from skimage.io import imsave\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import timeit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2iZmHNZHPJeY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Installing PyDrive\n"
      ]
    },
    {
      "metadata": {
        "id": "sQcsQ3W4XMjN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QQTP8GZ-uRe2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get Revelant Folders"
      ]
    },
    {
      "metadata": {
        "id": "0YF-FOtgmWdl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fileId = drive.CreateFile({'id': '1SacGLfWETpAZCSElYqPd4vy88_1ducIp'}) \n",
        "fileId.GetContentFile('Dataset.zip')  # Save Drive file as a local file\n",
        "\n",
        "fileId = drive.CreateFile({'id': '14QOpq2qoxU6wJZ3gUj5a9BHTPgr0e38C'}) \n",
        "fileId.GetContentFile('Result.zip')  # Save Drive file as a local file\n",
        "\n",
        "!unzip Dataset.zip -d ./\n",
        "!unzip Result.zip -d ./"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "atj37_qKPbOL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get Training data\n"
      ]
    },
    {
      "metadata": {
        "id": "zMlosvCnROBN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "#from keras.backend import one_hot \n",
        "\n",
        "# Get images to train\n",
        "TrainImages = []\n",
        "for filename in os.listdir('Dataset/Train/'):\n",
        "    TrainImages.append(img_to_array(load_img('Dataset/Train/'+filename)))\n",
        "TrainImages = np.array(TrainImages, dtype=float)\n",
        "\n",
        "\n",
        "TrainImages = 1.0/255*TrainImages\n",
        "\n",
        "Xtrain = rgb2lab(TrainImages)[:,:,:,0] #grayscale\n",
        "Ytrain = rgb2lab(TrainImages)[:,:,:,1] #ab colorspace\n",
        "\n",
        "#Z = one_hot(Ytrain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sZXvdr86lsRF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN architecture"
      ]
    },
    {
      "metadata": {
        "id": "RlJDrf3xu-Kw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(256, 256, 1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(313, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "'''model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))'''\n",
        "\n",
        "model.add(Conv2D(2, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hsqRh9IbM63P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(256, 256, 1)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(2, (3, 3), activation='softmax', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RFmCtoo5ROBR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bias = False\n",
        "\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(256, 256, 1)))\n",
        "\n",
        "#Conv1\n",
        "model.add(Conv2D(filters = 64, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(Conv2D(filters = 64, kernel_size = 3, strides=2, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(UpSampling2D((2, 2)))\n",
        "\n",
        "#Conv2\n",
        "model.add(Conv2D(filters = 128, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(Conv2D(filters = 128, kernel_size = 3, strides=2, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(UpSampling2D((2, 2)))\n",
        "\n",
        "#Conv3\n",
        "model.add(Conv2D(filters = 256, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(Conv2D(filters = 256, kernel_size = 3, strides=2, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(Conv2D(filters = 256, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(UpSampling2D((2, 2)))\n",
        "\n",
        "#Conv4\n",
        "model.add(Conv2D(filters = 512, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(Conv2D(filters = 512, kernel_size = 3, strides=2, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(filters = 512, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(UpSampling2D((2, 2)))\n",
        "\n",
        "#Conv5\n",
        "model.add(Conv2D(filters = 512, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias,dilation_rate=1))\n",
        "model.add(Conv2D(filters = 512, kernel_size = 3, strides=2, activation='relu', padding='same',use_bias=bias,dilation_rate=1))\n",
        "model.add(Conv2D(filters = 512, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias,dilation_rate=1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "\n",
        "#Conv6\n",
        "model.add(Conv2D(filters = 512, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias,dilation_rate=1))\n",
        "model.add(Conv2D(filters = 512, kernel_size = 3, strides=2, activation='relu', padding='same',use_bias=bias,dilation_rate=1))\n",
        "model.add(Conv2D(filters = 512, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias,dilation_rate=1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "\n",
        "#Conv7\n",
        "model.add(Conv2D(filters = 512, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(Conv2D(filters = 512, kernel_size = 3, strides=2, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(Conv2D(filters = 512, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(BatchNormalization())\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "\n",
        "#Conv8\n",
        "#model8up \n",
        "model.add(Conv2DTranspose(filters = 256, kernel_size = 4, strides=2, activation='relu', padding='same',use_bias=bias))\n",
        "\n",
        "model.add(Conv2D(filters = 256, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(Conv2D(filters = 256, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(Conv2D(filters = 256, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(UpSampling2D((2, 2)))\n",
        "\n",
        "#model.add(Conv2D(filters = 313,kernel_size=1,activation='softmax'))\n",
        "\n",
        "#Conv9\n",
        "model.add(Conv2DTranspose(filters = 128, kernel_size = 4, strides=2, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(Conv2D(filters = 128, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(Conv2D(filters = 128, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(Conv2D(filters = 128, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#Conv10\n",
        "model.add(Conv2DTranspose(filters = 128, kernel_size = 4, strides=2, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(Conv2D(filters = 128, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(Conv2D(filters = 128, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(Conv2D(filters = 128, kernel_size = 3, strides=1, activation='relu', padding='same',use_bias=bias))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters = 2, kernel_size = 3, strides=1, activation='softmax', padding='same',use_bias=False))\n",
        "#model.add(UpSampling2D((2, 2)))\n",
        "\n",
        "#model.add(Activation('softmax')) #will give Z hat\n",
        "#model.add(Activation('softmax'))\n",
        "#Adam\n",
        "#rmsprop\n",
        "model.compile(optimizer='rmsprop', loss='mse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aNxSytAmc_5k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Probability Distributions"
      ]
    },
    {
      "metadata": {
        "id": "0xoWVGBCdASy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Z = H^-1(Ytrain) \n",
        "# loss on Z_ and Z\n",
        "# Y_ = H(z_)\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xbydC4x_l4VW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training our model\n"
      ]
    },
    {
      "metadata": {
        "id": "2b9wzXM6ROBW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Image transformer\n",
        "#Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches).\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=20,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "# Generate training data\n",
        "batch_size = 30\n",
        "\n",
        "def image_a_b_gen(batch_size):\n",
        "    for batch in datagen.flow(TrainImages, batch_size=batch_size):\n",
        "        lab_batch = rgb2lab(batch)\n",
        "        X_batch = lab_batch[:,:,:,0] #grayscale\n",
        "        Y_batch = lab_batch[:,:,:,1:] / 128 #ab colorsapce /128 to normalize\n",
        "        yield (X_batch.reshape(X_batch.shape + (1,) ), Y_batch)\n",
        "\n",
        "# Train model  \n",
        "tensorboard = TensorBoard(log_dir=\"output/first_run\")\n",
        "model.fit_generator(image_a_b_gen(batch_size), callbacks=[tensorboard], epochs=50, steps_per_epoch=10,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jguQEAPal_G7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Saving our model"
      ]
    },
    {
      "metadata": {
        "id": "faWpxbCNROBa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UoE6sMCUmD4G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Testing the accuracy of the model"
      ]
    },
    {
      "metadata": {
        "id": "a8cMGVPrROBd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Test images\n",
        "\n",
        "TestImages = []\n",
        "for filename in os.listdir('Dataset/Test/GroundTruth/'):\n",
        "    if filename == \".DS_Store\":\n",
        "      continue\n",
        "    else:\n",
        "      TestImages.append(img_to_array(load_img('Dataset/Test/GroundTruth/'+filename)))\n",
        "TestImages = np.array(TestImages, dtype=float)\n",
        "\n",
        "\n",
        "#convert test images to lab colorspace\n",
        "Xtest = rgb2lab(1.0/255*TestImages)[:,:,:,0] #grayscale version\n",
        "Xtest = Xtest.reshape(Xtest.shape+(1,))\n",
        "\n",
        "Ytest = rgb2lab(1.0/255*TestImages)[:,:,:,1:] #ab colorspace\n",
        "Ytest = Ytest / 128 #normalize\n",
        "\n",
        "print(model.evaluate(Xtest, Ytest, batch_size=batch_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oqKxanKlmKNM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Color grayscale images"
      ]
    },
    {
      "metadata": {
        "id": "QNK1x3fKROBh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "color_me = []\n",
        "for filename in os.listdir('Dataset/Test/Grayscale/'):\n",
        "    if filename == \".DS_Store\":\n",
        "      continue\n",
        "    else:\n",
        "      color_me.append(img_to_array(load_img('Dataset/Test/Grayscale/'+filename)))\n",
        "\n",
        "color_me = np.array(color_me, dtype=float)\n",
        "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
        "color_me = color_me.reshape(color_me.shape+(1,))\n",
        "\n",
        "# Test model\n",
        "output = model.predict(color_me)\n",
        "output = output * 128\n",
        "\n",
        "# Output colorizations\n",
        "for i in range(len(output)):\n",
        "    cur = np.zeros((256, 256, 3))\n",
        "    cur[:,:,0] = color_me[i][:,:,0]\n",
        "    cur[:,:,1:] = output[i]\n",
        "    path = \"Result/img_\"+ str(i)+\".jpg\"\n",
        "    imsave(path, lab2rgb(cur))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q_ZSDPWIROBj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}